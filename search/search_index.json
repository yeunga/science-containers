{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Official CANFAR Science Platform Documentation","text":""},{"location":"#introduction-and-access","title":"Introduction and Access","text":"<p>The CANFAR Science Platform consists of set of services and resources to enable cloud-based astronomy data analysis.  Browser-based access to CANFAR's cloud computing layer is provided via authorized access to the CANFAR Portal. A Canadian Astronomy Data Centre (CADC) account that has been authorized to use the Portal is required.</p> <ul> <li>To request a CADC Account:  https://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/en/auth/request.html</li> <li> <p>Authorization to access the CANFAR Portal:</p> <ul> <li>If the project you are using the resource for is part of a collaboration already using the CANFAR Science Portal, ask the administrator of the collaboration you belong to add you as a member of the collaborations access group using the CADC Group Management Interface</li> <li>If your project is not part of an authorized collaboration, the collaboration lead will need to request access by sending an email to support@canfar.net specifying they are requesting access to the CANFAR Science Portal, the scale of resources needed (storage and cores of compute) and a short (few line) resource justification.  Canadian research collaborations are encouraged to apply for CANFAR Science Portal authorization.</li> </ul> </li> </ul> <p>The CANFAR Science Portal runs software packaged in containers. The portal allows users to run both pre-built, shared containers or private, custom containers. Authorized collaboration members can publish container images to the CANFAR Container Images Registry.  We have specific documentation on how to build and publish containers capable of being launched within the CANFAR Science Portal.</p> <p>The CANFAR Science Platform supports both launching interactive sessions (via the Portal) and non-interactive ones (using cURL or a dedicated Python module). More detailed documentation on launching a computing session on the CANFAR Science Portal can be found here. </p>"},{"location":"#interactive-sessions","title":"Interactive Sessions","text":"<p>Interactive sessions are applications running on the CANFAR cloud infrastructure and are accessed via a web browser, allowing users to interact with the (typically large) datasets hosted on CANFAR Science Platform storage. There are a few types of Interactive Sessions that cab be launched through the portal:</p>"},{"location":"#notebooks","title":"Notebooks","text":"<p>Notebooks are using the Jupyter Lab interface.</p>"},{"location":"#carta","title":"CARTA","text":"<p>CARTA (Cube Analysis and Rendering Tool for Astronomy) is an astronomy visualization tool that will run natively in the browser. It can read FITS or HDF5 files, often used in radio astronomy, but not only.</p>"},{"location":"#desktop","title":"Desktop","text":""},{"location":"#an-x11-desktop-session-that-enables-running-applications-in-the-science-platform-a-browser-desktop-session-can-be-launched","title":"An X11-desktop session that enables running applications in the Science Platform, a browser Desktop session can be launched.","text":"<ul> <li>Desktop documentation and tutorials are described in more detail in the User Documentation</li> <li>Launching a CASA window in the Desktop YouTube tutorial:  YouTube Tutorial</li> </ul>"},{"location":"#contributed","title":"Contributed","text":"<p>Contributed sessions are user-customised web applications, typically not maintained by CANFAR. This can be anything, such as a VSCode server and Pluto notebook for the Julia language. </p> <p>Please refer to the container documentation for more information on building contributed sessions.</p>"},{"location":"#batch-jobs","title":"Batch Jobs","text":"<p>Currently, the CANFAR Science Platform has a limited capacity for batch processing.  Batch processing can be understood  as a non-interactive executable launched on a container whose output is not attached to a display (headless). Please contact support@canfar.net before making use of the headless job support -- we are incrementally adding support for batch processing in the science platform. See the specific documentation. This is still experimental and the API may change.</p>"},{"location":"#storage","title":"Storage","text":"<p>All sessions and applications accessed through the Science Platform (interactive and batch) share a common storage system in the directory <code>/arc</code>. The primary folder/directories <code>/arc/home</code> and <code>/arc/projects</code>.  <code>/arc/home/${USERNAME}</code> contains a user's environment initializations details and personal information that might not be shared with collaboration members. <code>/arc/projects/${GROUP_NAME}</code> holds the data that the given group will be processing and the outputs of that processing. CANFAR encourages the use of <code>/arc/projects</code> for most data, and <code>/arc/home</code> for personalized configuration and software.  By default a user's <code>/arc/home/${USER}</code> folder is not readable by others on the platform.</p> <p>An efficient and convenient way to access the <code>arc</code> storage outside the Science Platform is through <code>sshfs</code>. Here is the documentation.</p> <p>In addition to <code>sshfs</code> mentioned above, the <code>arc</code> storage is also accessible via an API that is exposed:</p> <ul> <li>Using the CANFAR storage management interface: https://www.canfar.net/storage/arc/list</li> <li>Using the VOSpace Python libraries</li> <li>Using the <code>/arc/files</code> URL endpoint documentation</li> </ul> <p>More detailed instructions on data transfer options are documented here: here</p> <p>Please take care to protect sensitive information by ensuring it is not publicly accessible.  File access control on <code>arc</code> is described in the next section.</p>"},{"location":"#groups-and-permissions","title":"Groups and Permissions","text":"<p>Projects are encouraged to use groups to manage access to resources, including files and directories/folders in the <code>arc</code> project storage, mounted at <code>/arc/projects</code> in every session.</p> <p>Groups and their memberships can be managed through the CANFAR groups web interface, here: https://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/en/groups/</p> <p>Once created, groups can be assigned to files and directories in arc storage directly from their interactive sessions, or through the CANFAR storage</p> <p>For more details on setting access permissions, see the documentation on file permissions</p>"},{"location":"#programmatic-access","title":"Programmatic Access","text":"<p>Session launching and management are through the <code>skaha</code> service. The <code>skaha</code> API definition and science platform service are here:  https://ws-uv.canfar.net/skaha</p>"},{"location":"#community-and-support","title":"Community and Support","text":"<p>Discussions of issues and platform features take place in the Science Platform Slack channel: Science Platform Slack Channel</p> <p>To report bugs and request new features, please use our GitHub pages:  - For the infrastructure and session, https://github.com/opencadc/science-platform/issues - For the containers: https://github.com/opencadc/science-containers/issues</p> <p>Contributions to the platform (including updates or corrections to the documentation) can be submitted as pull requests to this GitHub repository. We especially encourage science containers to be shared across the user community by making your published containers public.</p> <p>General inquiries can be made to support@canfar.net, and take a look at our FAQ.</p> <p></p>"},{"location":"complete/","title":"Official CANFAR Science Platform Documentation","text":""},{"location":"complete/#introduction-and-access","title":"Introduction and Access","text":"<p>The CANFAR Science Platform consists of set of services and resources to enable cloud-based astronomy data analysis.  Browser-based access to CANFAR's cloud computing layer is provided via authorized access to the CANFAR Portal. A Canadian Astronomy Data Centre (CADC) account that has been authorized to use the Portal is required.</p> <ul> <li>To request a CADC Account:  https://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/en/auth/request.html</li> <li> <p>Authorization to access the CANFAR Portal:</p> <ul> <li>If the project you are using the resource for is part of a collaboration already using the CANFAR Science Portal, ask the administrator of the collaboration you belong to add you as a member of the collaborations access group using the CADC Group Management Interface</li> <li>If your project is not part of an authorized collaboration, the collaboration lead will need to request access by sending an email to support@canfar.net specifying they are requesting access to the CANFAR Science Portal, the scale of resources needed (storage and cores of compute) and a short (few line) resource justification.  Canadian research collaborations are encouraged to apply for CANFAR Science Portal authorization.</li> </ul> </li> </ul> <p>The CANFAR Science Portal runs software packaged in containers. The portal allows users to run both pre-built, shared containers or private, custom containers. Authorized collaboration members can publish container images to the CANFAR Container Images Registry.  We have specific documentation on how to build and publish containers capable of being launched within the CANFAR Science Portal.</p> <p>The CANFAR Science Platform supports both launching interactive sessions (via the Portal) and non-interactive ones (using cURL or a dedicated Python module). More detailed documentation on launching a computing session on the CANFAR Science Portal can be found here. </p>"},{"location":"complete/#interactive-sessions","title":"Interactive Sessions","text":"<p>Interactive sessions are applications running on the CANFAR cloud infrastructure and are accessed via a web browser, allowing users to interact with the (typically large) datasets hosted on CANFAR Science Platform storage. There are a few types of Interactive Sessions that cab be launched through the portal:</p>"},{"location":"complete/#notebooks","title":"Notebooks","text":"<p>Notebooks are using the Jupyter Lab interface.</p>"},{"location":"complete/#carta","title":"CARTA","text":"<p>CARTA (Cube Analysis and Rendering Tool for Astronomy) is an astronomy visualization tool that will run natively in the browser. It can read FITS or HDF5 files, often used in radio astronomy, but not only.</p>"},{"location":"complete/#desktop","title":"Desktop","text":""},{"location":"complete/#an-x11-desktop-session-that-enables-running-applications-in-the-science-platform-a-browser-desktop-session-can-be-launched","title":"An X11-desktop session that enables running applications in the Science Platform, a browser Desktop session can be launched.","text":"<ul> <li>Desktop documentation and tutorials are described in more detail in the User Documentation</li> <li>Launching a CASA window in the Desktop YouTube tutorial:  YouTube Tutorial</li> </ul>"},{"location":"complete/#contributed","title":"Contributed","text":"<p>Contributed sessions are user-customised web applications, typically not maintained by CANFAR. This can be anything, such as a VSCode server and Pluto notebook for the Julia language. </p> <p>Please refer to the container documentation for more information on building contributed sessions.</p>"},{"location":"complete/#batch-jobs","title":"Batch Jobs","text":"<p>Currently, the CANFAR Science Platform has a limited capacity for batch processing.  Batch processing can be understood  as a non-interactive executable launched on a container whose output is not attached to a display (headless). Please contact support@canfar.net before making use of the headless job support -- we are incrementally adding support for batch processing in the science platform. See the specific documentation. This is still experimental and the API may change.</p>"},{"location":"complete/#storage","title":"Storage","text":"<p>All sessions and applications accessed through the Science Platform (interactive and batch) share a common storage system in the directory <code>/arc</code>. The primary folder/directories <code>/arc/home</code> and <code>/arc/projects</code>.  <code>/arc/home/${USERNAME}</code> contains a user's environment initializations details and personal information that might not be shared with collaboration members. <code>/arc/projects/${GROUP_NAME}</code> holds the data that the given group will be processing and the outputs of that processing. CANFAR encourages the use of <code>/arc/projects</code> for most data, and <code>/arc/home</code> for personalized configuration and software.  By default a user's <code>/arc/home/${USER}</code> folder is not readable by others on the platform.</p> <p>An efficient and convenient way to access the <code>arc</code> storage outside the Science Platform is through <code>sshfs</code>. Here is the documentation.</p> <p>In addition to <code>sshfs</code> mentioned above, the <code>arc</code> storage is also accessible via an API that is exposed:</p> <ul> <li>Using the CANFAR storage management interface: https://www.canfar.net/storage/arc/list</li> <li>Using the VOSpace Python libraries</li> <li>Using the <code>/arc/files</code> URL endpoint documentation</li> </ul> <p>More detailed instructions on data transfer options are documented here: here</p> <p>Please take care to protect sensitive information by ensuring it is not publicly accessible.  File access control on <code>arc</code> is described in the next section.</p>"},{"location":"complete/#groups-and-permissions","title":"Groups and Permissions","text":"<p>Projects are encouraged to use groups to manage access to resources, including files and directories/folders in the <code>arc</code> project storage, mounted at <code>/arc/projects</code> in every session.</p> <p>Groups and their memberships can be managed through the CANFAR groups web interface, here: https://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/en/groups/</p> <p>Once created, groups can be assigned to files and directories in arc storage directly from their interactive sessions, or through the CANFAR storage</p> <p>For more details on setting access permissions, see the documentation on file permissions</p>"},{"location":"complete/#programmatic-access","title":"Programmatic Access","text":"<p>Session launching and management are through the <code>skaha</code> service. The <code>skaha</code> API definition and science platform service are here:  https://ws-uv.canfar.net/skaha</p>"},{"location":"complete/#community-and-support","title":"Community and Support","text":"<p>Discussions of issues and platform features take place in the Science Platform Slack channel: Science Platform Slack Channel</p> <p>To report bugs and request new features, please use our GitHub pages:  - For the infrastructure and session, https://github.com/opencadc/science-platform/issues - For the containers: https://github.com/opencadc/science-containers/issues</p> <p>Contributions to the platform (including updates or corrections to the documentation) can be submitted as pull requests to this GitHub repository. We especially encourage science containers to be shared across the user community by making your published containers public.</p> <p>General inquiries can be made to support@canfar.net, and take a look at our FAQ.</p> <p></p>"},{"location":"complete/faq/","title":"CANFAR Science Platform FAQ","text":"<ul> <li>My session is stuck in the <code>Pending</code> state - This can imply that the platform is unable to launch your image.  There are a number of potential causes:</li> <li> <p>Often skaha fails to authorize you to https://images.canfar.net due to an expired <code>CLI Secret</code>.  Try resetting this value by logging into https://images.canfar.net (using the OIDC Login button), going to your User Profile, and updating your CLI Secret.  Once done you should delete the Pending session and try launching it again.</p> <ul> <li>If the image is proprietary and the CLI Secret update did not work, check with your project administrator to ensure you have been granted access to the project in https://images.canfar.net</li> <li>The session could be in a Pending state waiting for resources so that it can be scheduled.</li> <li>More information about the reason for the Pending state can be found using the logging mechanisms explained in Programmatic Access.</li> </ul> </li> <li> <p>How do I test a graphical container on my Mac?</p> </li> <li> <p>Enable \"Allow connections from network clients\" in XQuartz settings. Relaunch XQuartz.</p> </li> <li> <p>In terminal execute</p> <pre><code>&gt; xhost + 127.0.0.1\n</code></pre> </li> <li> <p>Launch docker run with the option</p> <pre><code>-e DISPLAY=host.docker.internal:0\n</code></pre> </li> </ul> <p>These steps were taken from https://medium.com/@mreichelt/how-to-show-x11-windows-within-docker-on-mac-50759f4b65cb</p> <p></p>"},{"location":"complete/headless/","title":"CANFAR Science Platform Headless Jobs","text":"<p>Please contact us before making use of the 'headless job' support--we are incrementally adding support for batch processing in the science platform.</p>"},{"location":"complete/headless/#create-an-image","title":"Create an image","text":"<p>Create an image as per the regular process of making containers available in the platform:  Publishing</p> <p>However, label it as <code>headless</code> in https://images.canfar.net to make it available for headless job launching.</p>"},{"location":"complete/headless/#launch-a-headless-job","title":"Launch a headless job","text":"<p>For the full details of the job launching API, see this section of the akaha API documentation:  https://ws-uv.canfar.net/skaha#!/Session_Management/post_session</p> <p>All jobs will be run as the calling user.  All jobs have the <code>/arc</code> filesystem mounted.</p> <p>Example: launch a headless job, overriding the command and providing two arguments:</p> <p><code>curl -E ~/.ssl/cadcproxy.pem https://ws-uv.canfar.net/skaha/v0/session -d \"name=headless-test\" -d \"image=images.canfar.net/skaha/terminal:1.1.2\" --data-urlencode \"cmd=touch\" --data-urlencode \"args=/arc/home/majorb/headless-test-1a /arc/home/majorb/headless-test-1b\"</code></p> <p>skaha will return the <code>sessionID</code> on a successful post (job launch).  The job will remain in the system for 1 hour after completion (success or failure).</p> <p>Job phases: - Pending - Running - Succeeded - Failed - Terminating - Unknown</p> <p>To view all sessions and jobs: <code>curl -E ~/.ssl/cadcproxy.pem https://ws-uv.canfar.net/skaha/v0/session</code></p> <p>To view a single session or job: <code>curl -E ~/.ssl/cadcproxy.pem https://ws-uv.canfar.net/skaha/v0/session/&lt;sessionID&gt;</code></p> <p>To view logs for session: <code>curl -E ~/.ssl/cadcproxy.pem https://ws-uv.canfar.net/skaha/v0/session/&lt;sessionID&gt;?view=logs</code></p> <p>This shows the complete output (stdout and stderr) for the image for the job.</p> <p>To view scheduling events for session: <code>curl -E ~/.ssl/cadcproxy.pem https://ws-uv.canfar.net/skaha/v0/session/&lt;sessionID&gt;?view=events</code></p> <p>Scheduling events will only be seen when there are issues scheduling the job on a node.</p>"},{"location":"complete/headless/#community-and-support","title":"Community and Support","text":"<p>Dicussions of issues and platform features take place in the Science Platform Slack Channel:  Science Platform Slack Channel</p> <p>Reporting of bugs and new feature requests can also be made as github issues:  https://github.com/opencadc/skaha/issues</p> <p>Contributions to the platform (including updates or corrections to the documentation) can be submitted as pull requests to this GitHub repository.</p> <p>General inquiries can be made to support@canfar.net</p>"},{"location":"complete/headless/#faq","title":"FAQ","text":"<ul> <li>My session is stuck in the <code>Pending</code> state - This can imply that the platform is unable to launch your image.  There are a number of potential causes:</li> <li> <p>Often skaha fails to authorize you to https://images.canfar.net due to an expired <code>CLI Secret</code>.  Try resetting this value by logging into https://images.canfar.net (using the OIDC Login button), going to your User Profile, and updating your CLI Secret.  Once done you should delete the Pending session and try launching it again.</p> <ul> <li>If the image is proprietary and the CLI Secret update did not work, check with your project administrator to ensure you have been granted access to the project in https://images.canfar.net</li> <li>The session could be in a Pending state waiting for resources so that it can be scheduled.</li> <li>More information about the reason for the Pending state can be found using the logging mechanisms explained in Programmatic Access.</li> </ul> </li> <li> <p>How do I test a graphical container on my Mac?</p> </li> <li>See the instructions to have container display shown on your Mac here:  Display ENV on OSX</li> </ul> <p></p>"},{"location":"complete/permissions/","title":"CANFAR Authorisations and Permissions","text":""},{"location":"complete/permissions/#seesion-authorisations","title":"Seesion Authorisations","text":"<p>The session launching and management is through the <code>skaha</code> service The skaha API definition and science platform service are here:  https://ws-uv.canfar.net/skaha</p>"},{"location":"complete/permissions/#authentication","title":"Authentication","text":"<p>All requests to the skaha API must be made with CADC credentials.  In the science platform the credentials are handled with cookies, but for programatic access, either x.509 client certificates or authorization tokens must be used.</p>"},{"location":"complete/permissions/#authorization-tokens","title":"Authorization Tokens","text":"<p>Tokens can be obtained from the CANFAR Access Control service by providing your CADC username and password over a secure SSL connection:</p> <p><code>curl https://ws-cadc.canfar.net/ac/login -d \"username=&lt;username&gt;\" -d \"password=&lt;password&gt;\"</code></p> <p>The token returned can then be used for making authenticated requests to skaha.  For example:</p> <p><code>curl -H \"Authorization: Bearer &lt;token&gt;\" https://ws-uv.canfar.net/skaha/v0/session</code></p> <p>Tokens are valid for 48 hours.</p>"},{"location":"complete/permissions/#proxy-certificates","title":"Proxy Certificates","text":"<p>Another way to authenticate to the skaha API is by using proxy certificates.  Using the CADC Python libraries, the <code>cadc-get-cert</code> tool will download a proxy certificate to the default location: <code>$HOME/.ssl/cadcproxy.pem</code>.</p> <p><code>cadc-get-cert -u &lt;username&gt;</code></p> <p>By default the proxy certificate is valid for 10 days.  This can be modified (to a maximum of 30 days) with the <code>--days-valid</code> parameter.</p> <p>Instead of prompting for your password, cadc-get-cert can read it from your <code>$HOME/.netrc</code> file using the <code>--netrc-file</code> parameter.</p>"},{"location":"complete/permissions/#canfar-arc-file-system-groups-and-permissions","title":"CANFAR <code>arc</code> File System Groups and Permissions","text":"<p>Groups can be assigned as either <code>read-only</code> or <code>read-write</code>.</p> <p>More sophisticated management of groups, including setting default groups for a given project directory, can be done on the command line in the science portal, and is explained in the section below.</p>"},{"location":"complete/permissions/#command-line-group-management","title":"Command Line Group Management","text":"<p>Each file or directory can have any of read \u00ae, write (w), or execute (x) permission.  For example, a file with read-write permission is describe with rw-.</p> <pre><code>r = read - can see the file or directory\nw = write - can modify the file or directory\nx = execute - for directories, means list children.  for files, means execute file\n- = does not have the given permission (r, w, or x, depending on the position of the -)\n</code></pre> <p>The following lists permission combinations for arc as seen on the command line:</p> <pre><code>read-only file permissions: r--\nread-write file permissions: rw-\nread-only directory permissions: r-x\nread-write directory permissions: rwx\n</code></pre> <p>Group permissions are stored in POSIX Access Control Lists (ACLs).  To view the group permissions on a given file or directory, run the following command:</p> <pre><code>getfacl file-or-directory\n</code></pre> <p>There are two relevant entries in the output:</p> <p>The named-group permissions, in the format <code>group:{group-name}:{permissions}</code>.  For example: <code>group:skaha-users:rw-</code></p> <p>Secondly, if a <code>mask</code> entry exists, it will change the actual (or effictive) permissions the group receives.  For example, if the following mask entry <code>mask::r-x</code> were applied to <code>group:skaha-users:rw-</code>, the effective permissions become <code>group:skaha-users:r--</code>  Effective permissions are calculated by doing an AND operation on each of the three correspsonding permissions (rwx).  The permission must exist in both the original group permissions and the mask for them to become effective.  If a mask entry does not exist, the group permissions are used directly.</p> <p>To make files and directories (and their children) inherit group permissions, run one of the following commands:</p> <p>Set the default read group: <pre><code>setfacl -d -m group:{group-name}:r-x {read-only-dir}\n</code></pre></p> <p>Set the default read-write group: <pre><code>setfacl -d -m group:{group-name}:rwx {read-write-dir}\n</code></pre></p> <p>The group permissions are not set on target directories themselves, only on newly created children. To set group permissions on a single file or directory, run one of the following commands:</p> <p>Set the read group: <pre><code>setfacl -m group:{group-name}:r-x {read-only-dir}\n</code></pre></p> <p>Set the read-write group: <pre><code>setfacl -m group:{group-name}:rwx {read-write-dir}\n</code></pre></p> <p>To set group permissions on an existing directory tree recursively, run one of the following commands:</p> <p>Set the read group: <pre><code>setfacl -R -m group:{group-name}:r-x {read-only-dir}\n</code></pre></p> <p>Set the read-write group: <pre><code>setfacl -R -m group:{group-name}:rwx {read-write-dir}\n</code></pre></p> <p>To set group permissions on an existing directory tree recursively, and to have new children in directories of that tree inherit the group permissions, run one of the following commands:</p> <p>Set the read group: <pre><code>setfacl -R -d -m group:{group-name}:r-x {read-only-dir}\n</code></pre></p> <p>Set the read-write group: <pre><code>setfacl -R -d -m group:{group-name}:rwx {read-write-dir}\n</code></pre></p> <p></p>"},{"location":"complete/publishing/","title":"CANFAR Science Platform Containers","text":""},{"location":"complete/publishing/#introduction","title":"Introduction","text":"<p>The CANFAR Science Platform supports various types of containers: <code>session</code>, <code>software</code>,  and <code>legacy desktop application</code></p> <ul> <li><code>Session</code> are containers launched as native browser interactive applications (i.e. HTML5/Websocket).</li> <li><code>Software</code> are containers launched with any kind of executable, installed with custom software stack. </li> <li><code>Legacy desktop application</code> are containers launched and viewed specifically through a desktop <code>session</code>.  </li> </ul>"},{"location":"complete/publishing/#building-canfar-science-platform-containers","title":"Building CANFAR Science Platform Containers","text":""},{"location":"complete/publishing/#minimum-requirements","title":"Minimum requirements","text":"<ul> <li>Containers must be based on a standard Linux x86_84 distribution.</li> <li>Containers must contain an SSSD client and have ACL capabilities if one want to interact with the <code>arc</code> storage</li> </ul>"},{"location":"complete/publishing/#sssd-and-acl","title":"SSSD and ACL","text":"<p>For linux group id (<code>gid</code>) names to be resolved, the container must have an SSSD client and ACL tools installed, and must provide an <code>nsswitch.conf</code> file as described below.  If any of these are missing, only group IDs will be displayed (when <code>id</code> is typed for example), but file system authorization will continue to work as expected. The packages to install on a Debian-based Linux distribution are <code>sssd-client</code> and  <code>acl</code>.</p> <p>The file <code>/etc/nsswitch.conf</code> must include the <code>sss</code> module in the <code>passwd</code>, <code>shadow</code>, and <code>group</code> entries.  For example:</p> <pre><code>passwd:     sss files\nshadow:     files sss\ngroup:      sss files\n</code></pre>"},{"location":"complete/publishing/#additional-requirements-for-legacy-desktop-application-containers","title":"Additional requirements for legacy desktop application containers","text":"<p>Examples of legacy desktop software containers are astronomy GUIs such as CASA, Topcat, Aladin, and customized containers such as Gemini processing containers which require desktop interaction.  Some of the recipes (Dockerfiles) for building these containers can be found in the desktop directory.  They can also be managed and hosted elsewhere. However, wherever the source is hosted, containers must meet a minimal set of requirements and expectations for execution in skaha. Also the default executuable is <code>xterm</code>, so ensure it is installed.</p> <p>Note: the desktop session is also sometimes known as the ARCADE software environment.</p>"},{"location":"complete/publishing/#initialization-and-startup","title":"Initialization and Startup","text":""},{"location":"complete/publishing/#running-container-process-owners","title":"Running container process owners","text":"<p>Containers in the CANFAR Science Platform are always executed as the CADC User and never as root. Operations that require root must be done at the build phase of the image.  If runtime root access is required, it can possibly be done by giving sudo access to specific actions.</p>"},{"location":"complete/publishing/#session-container-initialization","title":"Session container initialization","text":"<p>Initialization for session containers is based on the session container type.  There are currently four types with different startup procedures: 1. <code>notebook</code>: it requires a <code>jupyter lab</code> executable 1. <code>carta</code>: initialization and startup is done through a customized script 1. <code>desktop-app</code>: desktop session startup is managed by the skaha infrastructure. 1. <code>contributed</code>: it will follow a customized startup script</p> <p>There may be multiple versions of the same type of session container, but the startup procedure for these must remain the same for them to be of the same type.</p>"},{"location":"complete/publishing/#contributed-session-containers","title":"Contributed session containers","text":"<p>Contributed sessions are for custom-build, web-browser applications that are not officially created and maintained by CANFAR. The rules of building a container of type \"contributed\" on the CANFAR Science Platform are: 1. Incoming trafic will be over http (which may include websocket trafic) on port 5000 1. From the point of view of the container, requests will be received at the root path (/), but URLs in the browser will look like https:///, where  and  are subject to change. This path will initially be https://ws-uv.canfar.net/sessions/contrib/ 1. The instance will be started by a script in the image that must be available at /skaha/startup.sh and will be passed 1 parameter: the sessionid."},{"location":"complete/publishing/#software-container-initialization","title":"Software container initialization","text":"<p>The <code>CMD</code> and <code>EXECUTABLE</code> directives in a CANFAR container <code>Dockerfile</code> will be ignored on startup.  Instead, bash within an xterm will run. <code>CMD</code> and <code>EXECUTABLE</code> are still useful for testing containers outside of CANFAR.</p> <p>If the container needs to do any runtime initialization, that can be done in a script named <code>init.sh</code> in the <code>/skaha</code> root directory.  This script must not block and needs to return control to the calling process.</p> <p>If <code>/skaha/init.sh</code> is provided, a sensible directive for testing the container via docker is <code>CMD [\"/skaha/init.sh\"]</code></p> <p>Another option is for containers to make available a file named <code>/skaha/startup.sh</code>.  If it exists, it will be called with a single parameter, which is the command <code>startup.sh</code> must run in order to execute on the platform.  So, the end of <code>startup.sh</code> should do: <code>exec \"$@\"</code> to execute the incoming parameter.  Containers should use startup.sh when environment must be made available to the context of the application.</p> <p></p>"},{"location":"complete/publishing/#publishing-skaha-containers","title":"Publishing skaha containers","text":""},{"location":"complete/publishing/#step-1-create-a-harbor-account","title":"Step 1: Create a harbor account","text":"<p>The CANFAR Science Platform hosts a private container registry. It is an instance of the Harbor open source project as a container registry. Session and software containers launched can be launched from this registry.</p> <p>If you have logged into harbor before then step 1 can be skipped.</p> <ol> <li>Go to https://images.canfar.net</li> <li>Press the <code>Login with OIDC Provider</code> button.</li> <li>Enter your CADC username and password.</li> <li>When prompter for a harbor userid, use your CADC username.</li> </ol> <p>After these steps you now have a harbor account and can see the project containers through its interface. If you wish to publish to any of the projects, contact the project admistrator (or contact support@canfar.net) and ask for 'Development' access to the project.</p>"},{"location":"complete/publishing/#step-2-docker-login-to-harbor","title":"Step 2: Docker login to harbor","text":"<ol> <li>From the harbor portal, go to the top right, click on your username, then go to 'User Profile'.</li> <li>Set your CLI secret -- this is the password to use for <code>docker login</code> commands.  You can copy the existing, generated secret, or 'upload' (enter) your own.</li> <li>From the computer on which you have built the docker image you wish to publish, do a docker login:</li> </ol> <p><code>docker login images.canfar.net</code></p> <p>Your user is your CADC username, and your password the value of the CLI Secret mentioned above.</p>"},{"location":"complete/publishing/#step-3-push-your-image-to-your-project","title":"Step 3: Push your image to your project","text":"<ol> <li>On the same computer, find the <code>IMAGE ID</code> of the image you'd like to push with the command</li> </ol> <p><code>docker images</code></p> <ol> <li>Tag the image for harbor:</li> </ol> <p><code>docker tag &lt;IMAGE ID&gt; images.canfar.net/&lt;PROJECT&gt;/&lt;MY IMAGE NAME&gt;:&lt;IMAGE VERSION&gt;</code> </p> <p>where:    * <code>&lt;PROJECT&gt;</code> is the project to which you've been granted Developer access.    * <code>&lt;MY IMAGE NAME&gt;</code> is the name of the image you are publishing.    * <code>&lt;IMAGE VERSION&gt;</code> is the version of the image.</p> <ol> <li>Push the image to harbor, with:</li> </ol> <p><code>docker push images.canfar.net/&lt;PROJECT&gt;/&lt;MY IMAGE NAME&gt;:&lt;IMAGE VERSION&gt;</code></p>"},{"location":"complete/publishing/#step-4-label-your-image-type","title":"Step 4: Label your image type","text":"<ol> <li>Go back to https://images.canfar.net</li> <li>Click on your project, then on your newly pushed image (also called a repository in harbor).</li> <li>Select the 'artifact' with the correct version (tag).</li> <li>Under the 'Actions' drop-down, apply the approripate label to the artifact.</li> </ol>"},{"location":"complete/publishing/#science-platform-actions","title":"Science Platform Actions","text":"<p>A number of the steps below can be done using the CANFAR Science Platform Portal at https://www.canfar.net</p>"},{"location":"complete/publishing/#listing-images-on-canfar","title":"Listing images on CANFAR","text":"<p>Once publishing and labeling has been completed, the image will be visible.  It can then be seen on the Science Platform Portal, or with the folowing command:</p> <p><code>curl -E &lt;cadcproxy.pem&gt; https://ws-uv.canfar.net/skaha/v0/image</code></p>"},{"location":"complete/publishing/#listing-resource-contexts","title":"Listing resource contexts","text":"<p>The available cores and RAM in skaha can be seen from the Science Platform, or viewed with:</p> <p><code>curl -E &lt;cadcproxy.pem&gt; https://ws-uv.canfar.net/skaha/v0/context</code></p> <p></p>"},{"location":"complete/publishing/#launching-containers","title":"Launching containers","text":""},{"location":"complete/publishing/#session-containers","title":"Session containers","text":"<ol> <li>Use the Science Platform Portal or this curl command to launch your newly published image:</li> </ol> <p><code>curl -E &lt;cadcproxy.pem&gt; https://ws-uv.canfar.net/skaha/v0/session -d \"name=&lt;arbitrary-name&gt;\" -d \"image=images.canfar.net/&lt;PROJECT&gt;/&lt;MY IMAGE NAME&gt;:&lt;IMAGE VERSION&gt;\"</code></p> <p>If non-default values for cores and/or ram is preferred, the parameters <code>-d cores=&lt;cores&gt;</code> and <code>-d ram=&lt;ram&gt;</code> can be added to the session launching command above.</p> <ol> <li>Use the Science Platform Portal or this curl command to find the URL to your session:</li> </ol> <p><code>curl -E &lt;cadcproxy.pem&gt; https://ws-uv.canfar.net/skaha/v0/session</code></p> <p>If this is the first time this image has been launched in may take a few minutes for the cloud do retrieve the image from harbor and send it to the selected node.</p>"},{"location":"complete/publishing/#software-containers","title":"Software containers","text":"<p>It should just run as is. See also headless containers.</p>"},{"location":"complete/publishing/#legacy-desktop-application-containers","title":"Legacy desktop application containers","text":"<p>Once a legacy desktop software container has been pushed to harbor, it must be labelled with <code>desktop-app</code>.</p> <p>To then make it appear in the <code>Applications-&gt;Astro Software</code> menu on the desktop a new desktop session must be started.</p> <p>The desktop menu items in <code>Applications-&gt;Astro Software</code> are organized by harbor project.  A sub-folder is created for each project.  Then, each version of the artifacts (images) within that project will be displayed in the project sub-folder.  For example, the desktop-app image identified by URI:</p> <p><code>images.canfar.net/skaha/terminal:1.0</code></p> <p>will be placed in the desktop menu like so:</p> <p><code>Applications -&gt; Astro Software -&gt; skaha -&gt; terminal:1.0</code></p> <p></p>"},{"location":"complete/publishing/#testing","title":"Testing","text":"<p>Before publishing a new or modified image, testing should be done to ensure it works as expected.</p> <p>For session containers, nearly all testing can be done by using <code>docker</code> to run the image.  A port should be exposed so you can connect your browser to the locally running session.</p> <p>For legacy desktop application containers, docker will not be able to provide a graphical display of CASA windows, so most testing must be done in a skaha-desktop instance running in the cloud.</p> <p>The only requirement for a container is to ensure the web application to be launched with a <code>/skaha/startup.sh</code> script in the container, and the web application running on port 5000.</p> <p></p>"},{"location":"complete/science-containers/","title":"CANFAR Science Platform User Containers","text":"<p>This repository (science-containers.git) includes build recipes for containers to be launched on the CANFAR science-platform.  Please feel free to contribute.</p>"},{"location":"complete/science-containers/#canfar-maintained-containers","title":"CANFAR-maintained Containers","text":"<p>Curently the repository contains basic build system to build a hierarchy of default containers supported by CANFAR:</p> <pre><code>                        Ubuntu LTS\n                            |\n                    base (headless)\n                            |\n        _____________________ _ _ _ _ _ _ _\n        |                                  | \nastroml (headless)          Desktop Application (desktop-app)\n        |\nastroml-notebook (notebook) \nastroml-vscode   (contributed)\nastroml-desktop  (desktop-app)\n</code></pre> <ul> <li>The <code>base</code> is a <code>headless</code> container are built from a vanilla Ubuntu LTS, with extra operating system installed (compilers, development libraries), and conda install.</li> <li>The <code>astroml</code> is another <code>headless</code> container and is built with a large set of astronomy, machine learning, deep learning, visualisations and data science libraries. </li> <li>The <code>astroml-*</code> add visualisation and interactivity software. They can be launched as a <code>notebook</code> session, a <code>contributed</code> VSCode session, or a terminal through a <code>desktop</code> session.</li> <li>The <code>Desktop Application</code> containers do not typically derive from <code>astroml</code> and sometimes not from <code>base</code> containers, as they are legacy and may rely on now unsupported OS.</li> </ul> <p>There are CUDA-enabled versions of the containers, which include NVIDIA software and CUDA-powered libraries. They are built and named as <code>*-gpu</code>, i.e. <code>astroml-gpu</code>, <code>astroml-gpu-notebook</code>.</p>"},{"location":"complete/science-containers/#canfar-user-customised-container","title":"CANFAR User Customised Container","text":"<p>If you want to build your own containers, documentation can be found in the docs directory. This directory also contains the building of the CANFAR usage documentation in the readthedocs style.</p>"},{"location":"complete/science-containers/#todo","title":"TODO","text":""},{"location":"complete/science-containers/#laundry-list-for-possible-actions","title":"Laundry list for possible actions","text":"<ul> <li>write a Makefile allowing: <code>make build astroml</code></li> <li>install jupyterlab extensions in home directory rather than /opt/conda</li> <li>configure jupyterlab containers to automatically creating directories  somewhere less intrusive than just <code>$HOME</code>:  <code>migrated astropy matplotlib yarn lab pip fontconfig serverconfig jedi numba</code></li> <li>launcher in jupyterlab has too many launching and confusing icons</li> <li>make a button on jupyterlab that will create a new environment automatically and create an icon</li> <li>build npm apps on container directories to avoid populating million of useless files</li> <li>environments in home directory with pip by default</li> <li>add other alternative notebooks such as querybook, cocalc, nteract_on_jupyter</li> </ul>"},{"location":"complete/science-platform/","title":"CANFAR Science Platform Infrastructure","text":"<p>The repository for the platform service infrastructure and deployment configuration is at:  https://github.com/opencadc/science-platform</p> <p></p>"},{"location":"complete/science-portal/","title":"CANFAR Science Portal","text":"<p>The CANFAR Science Portal runs at https://www.canfar.net It has the following services:</p> <ul> <li>Science Platform UI:  Science Platform UI</li> <li>Storage Management UI:  Storage Management UI (for both 'vault' and 'arc')</li> <li>Group Management UI:  Group Managment UI</li> <li>DOI Publication Service:  DOI Publication Service</li> </ul> <p></p>"},{"location":"general/","title":"Welcome to the documentation for CANFAR's Science Portal!","text":"<p>The CANFAR Science Portal provides astronomers the computing resources they need to work with their data. In addition to the documentation here, aimed at newer users, more advanced topics are covered at https://github.com/opencadc/science-containers/tree/main/doc</p> <p>Please acknowledge the CANFAR Science Portal in any resulting publications with the following:</p> <p>The authors acknowledge the use of the Canadian Advanced Network for Astronomy Research (CANFAR) Science Platform. Our work used the facilities of the Canadian Astronomy Data Center, operated by the National Research Council of Canada with the support of the Canadian Space Agency, and CANFAR, a consortium that serves the data-intensive storage, access, and processing needs of university groups and centers engaged in astronomy research (Gaudet et al 2010).</p>"},{"location":"general/ALMA_Desktop/archive_download/","title":"Download data from the ALMA archive (web browser)","text":"<p>Downloading data directly from an ALMA archive web query is quite straightforward. Double-click on the Firefox icon on the desktop, and navigate to the ALMA archive.</p> <p></p> <p>You can use the filters to help identify the data you are interested in. For more information on using the archive query effectively, see this instructional video: https://almascience.nrao.edu/alma-data/archive/archive-video-tutorials</p> <p>Select the dataset(s) of interest by ticking the box(es) to the left of each project.</p> <p></p> <p>On the upper right panel, click the downward-pointing arrow, then click the green <code>Explore and download</code> button that pops up.</p> <p></p> <p>In the next window that pops up, select the files that you are interested in and click <code>Download Selected</code>.</p> <p></p> <p>In the pop up window that next appears, click the <code>Download Script</code> button.</p> <p></p> <p>Save this file to your desktop session.</p> <p></p> <p>To locate the file, click the downward-pointing arrow in the top left of the firefox browser, and then double-click the folder icon in the right of the window that pops up.</p> <p></p> <p>This will open the File Manager in the directory where your ALMA data download script has been saved. The default is usually under Downloads/ within your home directory.</p> <p></p> <p>Open a terminal (double-click the terminal icon), go to the Downloads directory, and run the data download script.</p> <p></p> <p>When all of the files have been downloaded, you should see a query about un-tarring (uncompressing) them. Click <code>y</code> for yes.</p> <p></p> <p>You can now open a CASA terminal to begin your data reduction or analysis.</p>"},{"location":"general/ALMA_Desktop/archive_script_download/","title":"Download data from the ALMA archive (transfer script)","text":"<p>Downloading data from the ALMA archive directly using a web query is shown in this tutorial.  Some users, however, may prefer to interact with the ALMA archive on their local machine and instead transfer the resulting data download script to their Desktop session. For more information on using the archive query effectively, see this instructional video: https://almascience.nrao.edu/alma-data/archive/archive-video-tutorials</p> <p>Once you have a data download script on your local computer, there are a variety of methods to transfer files into your Science Portal diskspace. Once the script is uploaded and thus accessible to your Desktop session, you can run the script within a terminal container and download the data, as shown in this tutorial.</p>"},{"location":"general/ALMA_Desktop/start_casa/","title":"Starting CASA","text":"<p>Once you have launched a Desktop session, it is straightforward to run CASA in a terminal.</p> <p></p> <p>To start a CASA-enabled terminal, first click on the <code>Applications</code> menu at the top left corner of your screen</p> <p></p> <p>Click through the <code>AstroSoftware</code> and main CASA version to select the specific version that you want to use. Every version of CASA back to CASA 3.4.0 is available (this is the version of CASA which is tied to the scripts distributed with ALMA Cycle 0 data on the archive; see link here)</p> <p></p> <p>Clicking on your prefered version of CASA will open a terminal in which you can run CASA in the standard manner (typing either <code>casa</code> or <code>casa --pipeline</code> depending on the mode you wish to use). (NB: there are two dashes before <code>pipeline</code> in the previous command)</p> <p></p> <p></p> <p>You can open a regular (non-CASA) terminal by double-clicking the <code>terminal</code> icon at the lower left side of the screen. Note that each terminal has a label on top which denotes what type of terminal it is (i.e., a plain terminal or the CASA version that is enabled). Only basic linux commands are recognized in the CASA terminals, so it is preferable to use a non-CASA terminal for all regular linux uses.</p> <p></p>"},{"location":"general/ALMA_Desktop/typical_reduction/","title":"Example: reduce and image data","text":"<p>This tutorial walks through an example of reducing and imaging and ALMA dataset, and copying the final images to a personal computer. First, you need to download your ALMA data onto your Desktop Session. See here or  here for tutorials on how to download data directly from the ALMA Science Archive, or here for instructions on how to transfer files from your personal computer or VOSpace to the Desktop Session, if you already have your ALMA data downloaded there.</p> <p>Next, open a CASA container (see this tutorial with the version that you need to run. Then, start CASA in either interactive or pipeline mode, depending on what is required for your reduction script, by typing <code>casa</code> or <code>casa --pipeline</code></p> <p>Note: The version of CASA originally used to reduce your dataset can usually be found listed in the log files and/or near the top of the reduction scripts. At present, it is generally recommended that you use the same version of CASA to reduce the data as was originally used. The presence of scripts with <code>pipe</code> in their names in the script directory indicate that CASA must be initiated in pipeline mode.</p> <p></p> <p>Once you have started CASA, run the data reduction script (usually called scriptForPI.py) by typing <code>execfile('scriptForPI.py')</code></p> <p></p> <p>After the reduction script runs, you will find the calibrated measurement set(s) in the calibrated/ directory. The scriptForImaging.py script that is usually distributed with the dataset will help you to image your dataset. Usually, this script needs to be copied into the calibrated/ directory before running it. In some instances, you may need to start up a different version of casa to run the script. In the example shown here, the calibration script uses the pipeline version of CASA (<code>casa-4.3.1-pipe</code>), while the imaging script uses the interactive version of CASA (<code>casa-4.3.1</code>), and these two CASA versions were distributed independently with the names as noted in parenthesis. Thus, to image the data, you would need to open a new <code>casa-4.3.1</code> container and type <code>casa</code> in the prompt.</p> <p>During imaging, you might find it helpful to open up a regular terminal to view and/or edit the imaging script, for example, to copy and paste the commands one line at a time into casa (see the Using the Clipboard tutorial for more information).</p> <p></p> <p>Interacting with the CASA viewer while running the tast tclean, for example, works in the same manner as on a personal desktop machine.</p> <p></p> <p>Once imaging and any desired analysis is complete, you can transfer your final files off of the system using one of the many options available to transfer files.</p> <p></p> <p>In the example above, a small subset of files are being transfered to a personal VOSpace page using the vcp command:</p> <pre><code>vcp calibrated_final_cont_image_162622-24225.* vos:helenkirk/\n</code></pre> <p>Note that the Science Portal is not intended to be used for long-term data storage needs - VOSpace is instead recommended as it has a robust backup system in place.</p>"},{"location":"general/General_tools/File_transfers/","title":"File Transfer Overview","text":"<p>There are a variety of methods available to move files into and out of the Science Portal. This page provides a short summary of the options, with links to further resources that are available.</p> <ul> <li>upload individual files in \\'Notebook\\': Small files can be easily     uploaded within a Notebook session using the upload icon. A tutorial     is available here</li> <li>upload/download files or directories using the web browser     interface for the     storage associated with the Science Portal. A tutorial is available     here.</li> <li>upload/download files or directories from the command line using the     VOS Tools software. See a basic tutorial     here.</li> <li>mount the file system to your local computer using sshfs. See a     basic tutorial here.</li> <li>command line interaction to upload/download files through a direct     url. See a brief description here.</li> </ul>"},{"location":"general/General_tools/Group_management/","title":"Group Management Tools","text":"<p>The group management tools allow you to define a set of people who have permission to read, write, or execute your files.</p> <p>Start by going to <code>canfar.net</code> and clicking on the Group Management icon.</p> <p></p> <p>You can then create a new <code>group</code> (list of CADC usernames) which you will be granting access to your files. Click on the <code>New Group</code> button to get started.</p> <p></p> <p>A pop up window will appear that allows you to provide a group name and brief description.</p> <p></p> <p>This group will then appear on the master list on the main page. You can add your collaborators by clicking the <code>Edit</code> button in the Membership column.</p> <p></p> <p>Start typing the name of your collaborator into the <code>Enter a name</code> box, and a window will pop up with matches that you can use to find the person. (NB: the search is based on the actual name and not CADC username). Once you have selected the person, click the <code>Add member</code> button. They will be added to the group even though the listing on the pop-up window is not auto-refreshed. You can close the pop-up window and click the <code>Edit</code> button a second time to confirm that they are now a member of your group.</p> <p></p> <p></p> <p>If you wish to grant others in the group permission to add further members, etc, you can do so by clicking the <code>Edit</code> button in the <code>Administrators</code> column and following the same procedure.</p> <p></p> <p>With your group created, you navigate to CANFAR's webpage for all projects, https://www.canfar.net/storage/arc/list/projects and edit file access there. In this example, the project directory is <code>ALMAcores</code>, and the group <code>HKirk_plus_grads</code> is already granted access to read and write files.</p> <p></p> <p>Click the pencil button to edit the group permissions. In this example, the current group with write permissions appears in the associated box.</p> <p></p> <p>Start typing in your desired group name, then select the group from the pop-up list.</p> <p></p> <p>Click the <code>Save</code> button</p> <p></p> <p>then click <code>Ok</code> on the pop-up window.</p> <p></p> <p>Your updated group permissions are now shown on the main page.</p> <p></p> <p>Management of groups can also be done via the command line, and is the prefered option for more complex settings. See this page for instructions.</p>"},{"location":"general/General_tools/Using_sshfs/","title":"Using SSHFS","text":"<p>SSHFS, or the secure shell file system, allows users to interact with the directories and files from their Science Portal account directly on their local machine.</p>"},{"location":"general/General_tools/Using_sshfs/#installation","title":"Installation","text":"<p>Software installation is required to use this tool.</p> <p>Linux: SSHFS is Linux-based software that needs to be installed on your local computer. On Ubuntu and Debian based systems, it can be installed through apt-get:</p> <pre><code>sudo apt-get install sshfs\n</code></pre> <p>Mac OSX: Often SSHFS is already installed; if not, you will need to download FUSE and SSHFS from the osxfuse site</p>"},{"location":"general/General_tools/Using_sshfs/#mount-the-remote-file-system","title":"Mount the Remote File System","text":"<p>For Ubuntu/Debian Linux or Mac OSX, the instructions are below. Instructions for Windows users can be found at the bottom of this page.</p> <p>To start, we will need to create a local directory in which to mount the file system, \"arc\":</p> <pre><code>mkdir $HOME/arc\n</code></pre> <p>Now we can mount the file system locally using the following command, based on which OS you are running. You will be asked for your CADC password during this step.</p> <p>On Ubuntu/Debian:</p> <pre><code>sshfs -o reconnect,ServerAliveInterval=15,ServerAliveCountMax=10 -p 64022 [your_cadc_username]@ws-uv.canfar.net:/ $HOME/arc\n</code></pre> <p>On Mac OSX:</p> <pre><code>sshfs -o reconnect,ServerAliveInterval=15,ServerAliveCountMax=10,defer_permissions -p 64022 [your_cadc_username]@ws-uv.canfar.net:/ $HOME/arc\n</code></pre> <p>The extra <code>defer_permissions</code> switch works around issues with OSX permission handling. See this page for more details.</p>"},{"location":"general/General_tools/Using_sshfs/#synch-local-and-remote-directories-with-rsync","title":"Synch Local and Remote Directories with rsync","text":"<p>With the steps above in place, the rsync (\"remote synch\") command can be used. rsync uses an algorithm that minimizes the amount of data copied by only moving the portions of files that have changed. Further rsync examples and docs are here.</p> <p>The synch is performed using the following:</p> <pre><code>rsync -vrltP source_dir $HOME/arc/destination_dir/\n</code></pre> <p>where</p> <ul> <li><code>-v</code> increases verbosity</li> <li><code>-r</code> recurses into directories</li> <li><code>-l</code> copies symlinks as symlinks</li> <li><code>-t</code> preserves modification times (use the command <code>man rsync</code> for     more details on why this option prevents resending already     transferred data when not using <code>-a</code>)</li> <li><code>-P</code> keeps partially transferred files and shows progress during     transfer</li> </ul> <p>Pro tip: including a <code>/</code> after source_dir in the command above will transfer the directory contents without the main directory itself. i.e., if your source_dir contains a file called test, then :</p> <pre><code>rsync -vrltP source_dir $HOME/arc/destination_dir/\n</code></pre> <p>will add in the file as <code>$HOME/arc/destination_dir/source_dir/test</code> whereas:</p> <pre><code>rsync -vrltP source_dir/ $HOME/arc/destination_dir/\n</code></pre> <p>will add in the file as <code>$HOME/arc/destination_dir/test</code></p>"},{"location":"general/General_tools/Using_sshfs/#unmounting-the-file-system","title":"Unmounting the File System","text":"<p>If you have finished working with your files and want to disconnect from the remote file system, you can do this by:</p> <pre><code>umount $HOME/arc\n</code></pre> <p>NB: If you run into problems with the original sshfs command and need to run it again, you will likely need to unmount first.</p>"},{"location":"general/General_tools/Using_vostools/","title":"Using VOS Tools","text":"<p>The most efficient way to transfer files in and out of CANFAR's Science Portal is to use the VOS Tools, which are also used for interacting with CANFAR's VOSpace.</p> <p>Instructions for installing VOS Tools on your personal computer are located here under the section titled The vos Python module and command line client.</p> <p>Instructions on how to use this tool, including some basic examples, are found on the same webpage. In brief, this tool runs on the command line with syntax similar to the linux <code>scp</code> command. File locations within CANFAR systems are specified with vos for VOSpace and arc for the Science Portal. For example, to copy a file from your personal computer to your home directory in the Science Portal, you would type the following command on your personal computer:</p> <pre><code>vcp myfile.txt arc:home/[username]\n</code></pre> <p>To copy a file from VOSpace to your personal computer, you would use:</p> <pre><code>vcp vos:[username]/myfile.txt ./\n</code></pre> <p>To copy files from the Science Portal to VOSpace, you would similarly use the command:</p> <pre><code>vcp myfile.txt vos:[username]\n</code></pre> <p>with the command being run on a terminal within the Science Portal. Note that it is not yet possible to initiate file transfers between the Science Portal and VOSpace from your personal computer.</p> <p>Also, you may have noticed that the base directory structure differs slightly between VOSpace and the Science Portal; the Science Portal includes a <code>home</code> directory, while VOSpace does not. Other commands such as vls to list files and vrm to remove/delete files may also be useful. Note that VOS Tools use a security certificate which needs to be updated periodically. If you get an error message stating:</p> <pre><code>ERROR:: Expired cert. Update by running cadc-get-cert\n</code></pre> <p>run the following command on your personal computer:</p> <pre><code>cadc-get-cert -u [username]\n</code></pre> <p>and enter your password for CADC/CANFAR services at the prompt. More information about VOS Tools can be found at: https://www.canfar.net/en/docs/storage/</p>"},{"location":"general/General_tools/Using_webstorage/","title":"Using Web Storage","text":"<p>For both VOSpace and the Science Portal, users can upload or download files via a web interface (at the links given). This page provides a quick tutorial on how to use the web interface, which is nearly identical for both systems. Note that for the Science Portal, users can alternatively upload or download files using direct URLs as outlined here.</p>"},{"location":"general/General_tools/Using_webstorage/#upload-files","title":"Upload File(s)","text":"<p>To upload one or more files (or folders), navigate to the desired directory, then click the <code>Add</code> button along the top, selecting the appropriate option. In this example, the directory of interest is in the Science Portal, in a directory called <code>Tutorial_example</code> in the user's home directory.</p> <p></p> <p>Follow the instructions on the pop-up box that appears next.</p> <p></p> <p></p> <p>Once the file is selected, click <code>Upload</code> and then <code>Ok</code>.</p> <p></p> <p></p> <p>Your file will now appear in the list for the directory.</p> <p></p>"},{"location":"general/General_tools/Using_webstorage/#download-files","title":"Download Files","text":"<p>Downloading files is also straightforward, and three options are outlined here. To begin, select the files you wish to download, and click the <code>Download</code> button from the menu bar. The <code>URL List</code>, <code>HTML List</code>, and <code>Zip</code> options are described below: the <code>Zip</code> option will usually be the most practical, but the <code>HTML List</code> option may be preferred when downloading only a few files, and <code>URL List</code> may be best for scripting (command line with no user interaction required).</p> <p></p>"},{"location":"general/General_tools/Using_webstorage/#download-url-list-option","title":"Download - URL List Option","text":"<p>For this method, you are downloading a list of URLs which you will then run additional commands on your local machine in order to grab the files themselves.</p> <p>First, choose the <code>URL List</code> option, then select the desired directory and file name and click <code>save</code>.</p> <p></p> <p>Next, unless the file(s) is/are publicly available, you will need to set up security certificates to access them via the command line. Do this by:</p> <pre><code>cadc-get-cert -u [username]\n</code></pre> <p>and entering your password at the prompt. You will need to have installed the VOStools package for this step. The command will generate a file called <code>~/.ssl/cadcproxy.pem</code> which contains the security certificate information. This certificate is valid for 10 days, so if you have already recently generated a certificate, you can skip the <code>cadc-get-cert</code> step.</p> <p>Now, you can run the command to download the files themselves:</p> <pre><code>wget --content-disposition -i cadcUrlList.txt --certificate ~/.ssl/cadcproxy.pem --ca-certificate ~/.ssl/cadcproxy.pem\n</code></pre> <p>where <code>cadcUrlList.txt</code> will need to be updated if you changed the originally downloaded file name from its default. At the end of this process, you will find the files in your current directory</p> <p></p> <p>NB: if you are downloading files from VOSpace and not the Science Portal, there is an alternative authentication method which does not require downloading VOStools. The syntax looks like this:</p> <pre><code>wget --content-disposition -i cadcUrlList.txt --http-user=[username] --ask-password\n</code></pre> <p>The remainder of the process is identical to what was outlined above.</p>"},{"location":"general/General_tools/Using_webstorage/#download-html-list-option","title":"Download - HTML List Option","text":"<p>Clicking the <code>HTML List</code> option will bring up a pop up window with a series of long URL strings - each (ususally 2-line) entry is a clickable direct link to your individual files. You can interact with these as you normally do with file download links. For example, you can left click the link to bring up a pop-up menu to tell your browser to directly download the file. Alternatively, you can right-click the link and your browser will display the file directly (for appropriate file types such as pdf). This method is clearly only sensible when you are looking to download a very small number of files.</p> <p></p>"},{"location":"general/General_tools/Using_webstorage/#download-zip-option","title":"Download - Zip Option","text":"<p>The <code>Zip</code> option allows you to download a single zip file containing all of your requested files. Choose the <code>zip</code> option, and click <code>save</code> in the pop-up window after adjusting your preferred directory and zip file name.</p> <p></p> <p>You can then unzip the file and interact with the files as usual. In this example (terminal on a Mac laptop), the file is unzipped using <code>open</code> and the files can thereafter be viewed in the unzipped directory.</p> <p></p>"},{"location":"general/NewUser/LaunchCARTA/","title":"Launching a CARTA session","text":"<p>After logging in to the Science Portal and clicking the plus sign to launch a new session, choose a session type of <code>carta</code>.</p> <p></p> <p>Note that the remaining menu bars and options update automatically after your session type selection. (Please be patient; sometimes it takes a few seconds to update.) There are currently three options for <code>container image</code>: choose the version of CARTA that you need here (1.4, 2.0, or 3.0 beta).</p> <p></p> <p>Give your session a descriptive name; this will later appear on your Science Portal page if you need to log in again later.</p> <p></p> <p>Next select the maximum amount of RAM that you anticipate requiring. It is best to choose the smallest value that is reasonable for your needs, as the computing resources are shared amongst all users. A very large RAM request may slow or prevent you from launching a session if the necessary resources are not currently available on the system. If you are unsure of what you need, the default value of 16GB is a safe assumption - it is the amount of RAM available on a MacBookPro.</p> <p></p> <p>Similarly, select the maximum number of computing cores that you anticipate requiring. As with the RAM, it is best to choose the smallest number that you expect to need. If you are unsure of what you need, the default value of 2 cores is likely sufficient. Most of the time, only one core would be required.</p> <p></p> <p>Now, hit the launch button and wait for your session to launch.</p> <p></p> <p>Congratulations! You've started your first CARTA session. You are automatically returned to the main Science Portal page, where your CARTA session appears as an icon, with your chosen descriptive name. Access the session by clicking on the session icon.</p> <p></p> <p>Wait while the session loads, after which you arrive at the main landing page.</p> <p></p> <p></p> <p>Now, navigate through to the file that you would like to display on CARTA. For information on how to upload files, see file transfers for the options available. This tutorial assumes that you have a file uploaded already. First, click the icon on the upper left to navigate up one directory.</p> <p></p> <p>Files saved in your desktop session can be found in the <code>home/[username]</code> or <code>home/[projectname]</code> directory. Click through the directory structure until you reach your desired file. Select the file and click the load button.</p> <p></p> <p>Congratulations! You're displaying your first image in CARTA!</p> <p></p>"},{"location":"general/NewUser/LaunchDesktop/","title":"Launching a Desktop session","text":"<p>After logging in to the Science Portal and clicking the plus sign to launch a new session, choose a session type of <code>desktop</code></p> <p></p> <p>Note that the remaining menu bars and options update automatically after your session type selection. (Please be patient, sometimes this takes a few seconds.) There is currently only one option for <code>container image</code>, so no selection is needed.</p> <p></p> <p>Give your session a descriptive name; this will later appear on your Science Portal page if you need to log in again later</p> <p></p> <p>Now, hit the launch button and wait for your session to launch</p> <p></p> <p>Congratulations! You've started your first Desktop session. You are automatically returned to the main Science Portal page, where your desktop session appears as an icon, with your chosen descriptive name. Access the session by clicking on the icon. Note that sometimes it takes a few seconds for the link to your session to work properly; if you are taken to a webpage that states <code>Bad gateway</code> when you click on the icon, simply wait a few more seconds and then try again.</p> <p></p> <p>This takes you to the landing page for your Desktop session. Click the connect button to connect to the session. When you session becomes inactive for some time, you are automatically returned to this page, but you can return to the session exactly where you left off by once again clicking the connect button.</p> <p></p> <p></p> <p>As you can see, this desktop session has a similar look and feel to a standard linux desktop that you may be familiar with. See the main page for tutorials on using various aspects of the Desktop session, including launching a CASA-enabled terminal.</p>"},{"location":"general/NewUser/LaunchNotebook/","title":"Launching a Notebook session","text":"<p>After logging in to the Science Portal and clicking the plus sign to launch a new session, choose a session type of <code>notebook</code>.</p> <p></p> <p></p> <p>Next, choose your prefered container image. The CASA6.5-notebook has CASA version 6.5 already installed.</p> <p></p> <p>Then add a descriptive name for your Notebook.</p> <p></p> <p>Next select the maximum amount of RAM that you anticipate requiring. It is best to choose the smallest value that is reasonable for your needs, as the computing resources are shared amongst all users. A very large RAM request may slow or prevent you from launching a session if the necessary resources are not currently available on the system. If you are unsure of what you need, the default value of 16GB is a safe assumption - it is the amount of RAM available on a MacBookPro.</p> <p></p> <p>Similarly, select the maximum number of computing cores that you anticipate requiring. As with the RAM, it is best to choose the smallest number that you expect to need. If you are unsure of what you need, the default value of 2 cores is likely sufficient. Most of the time, only one core would be required.</p> <p></p> <p>Next, click the <code>Launch</code> button to start the Notebook session.</p> <p></p> <p>Wait until a Notebook icon appears, then click on it to access your session.</p> <p></p> <p>Congratulations! You have now launched your first Notebook session. There are a variety of different applications available for you to use. In the Python 3 (ipykernel) Notebook icon in the top left, you can load and run CASA commands, as illustrated in the last image below.</p> <p></p> <p></p>"},{"location":"general/NewUser/Login/","title":"How to log in","text":"<p>You will need a CADC account to access the system. If you do not have one, you can request one here: https://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/en/auth/request.html</p> <p>To request authorization to use the Science Portal, send an email to support@canfar.net You may also wish to consider the following:</p> <ul> <li>Project space: If you intend to work on a dataset with     collaborators, it is recommended that you set up a     project space, where a     designated group of users all has common access to the files     contained within it. You will need to supply a project name and     estimated space requirement to the email address above.</li> <li>Communications on Discord: a Discord workspace is used for some     aspects of communication around the Science Portal, including notice     of service outages and some trouble-shooting support. You can     request that you be added to this space also by contacting the email     address listed above.</li> </ul> <p>Once your access has been confirmed, go to the CANFAR page: https://www.canfar.net and log in to access the Science Portal</p> <p></p> <p>Start a new session by clicking the plus sign</p> <p></p> <p>There are four different types of sessions that you can choose to launch: Desktop, CARTA, Notebook, and Contributed. All are described below; in brief, Desktop provides a linux desktop-like working environment, CARTA corresponds to ALMA's CARTA visualization tool, Notebook provides a Jupyter Notebook environment, and Contributed contains community-contributed tools such as a time estimator for the CASTOR mission. Start by selecting the session type in the upper drop-down menu; the options will automatically be re-populated for the remaining menu items.</p> <p></p> <p>See the following pages for the subsequent steps. Note that you can have at most three active sessions of any type.</p> <ul> <li>Desktop</li> <li>CARTA</li> <li>Notebook</li> </ul>"},{"location":"general/NewUser/Overview/","title":"Portal Overview","text":"<p>The CANFAR Science Portal allows users to access the tools and computing resources they need to conduct their research. This page provides a brief overview of the system, with a few important notes.</p>"},{"location":"general/NewUser/Overview/#containers","title":"Containers","text":"<p>Software packages (such as CASA for interferometry data) are run through software containers, which come pre-packaged with all of the necessary dependencies to run in a specific environment. Each software container, and the session that it is launched from (more on sessions below) can access your same common set of files, but on the back-end, may be running on a different computer in the cloud. Advanced users are encouraged to help create and maintain software containers which are useful for their research community, to help broaden the set of useful tools that the Science Platform is able to offer. Containers may take some time (a few minutes) to load if they have not previously been opened on the specific cloud computer previously that they are being called on. Please have patience!</p>"},{"location":"general/NewUser/Overview/#sessions","title":"Sessions","text":"<p>Users may choose to interact with their data in several different types of sessions. Each type is described briefly below. Users can run a maximum of three sessions, regardless of type, at the same time. Each session will run for a maximum of 4 days, but can be renewed indefinitely by clicking on the clock icon on the science portal landing page.  When a  session is terminated, any processes running in it will terminate, however, all of your files, etc, are preserved and will be accessible if, e.g., you launch a new session. While a session is active, you can close your browser and re-open the session later from the Science Portal landing page (on any computer), and all of your files, running processes, etc, will be as you left them.</p> <ul> <li>A Desktop session     provides a linux desktop-like environment in which to interact with     software containers; many commonly-used astronomy software packages     are available in the astrosoftware menu.</li> <li>A Notebook session     provides a Jupyter Notebook style of environment in which to     interact with your data and run software.</li> <li>A CARTA session runs     the CARTA image viewing software, which provides an efficient way to     examine large 3-D data cubes.</li> <li>The Contributed session provides access to community-created tools,     such as the CASTOR exposure time calculator.</li> </ul> <p>Note that all new sessions are launched from the main Science Portal page, https://www.canfar.net/science-portal/ You cannot, for example, launch a Notebook session from within a Desktop session.</p> <p>All of your files are simultaneously accessible from all active sessions, as well as several other modes such as this website: https://www.canfar.net/storage/arc/list/home and you may upload/download files via the methods described here.</p>"},{"location":"general/NewUser/Overview/#file-storage","title":"File Storage","text":"<p>There are a few important points to note about the file storage system on the Science Portal:</p> <ul> <li>CANFAR's VOSpace service     should be used for long-term stable file storage, as it includes     multiple backups at different geographical locations.</li> <li>Users can request space in both a personal home directory as well as     a 'project' space.     Use of project space for most analyses is highly encouraged, as     there are mechanisms available for users to easily share access to     files, etc with their collaborators there.</li> </ul>"},{"location":"general/NewUser/ProjectSpace/","title":"Setting up a Project Space","text":""},{"location":"general/NewUser/ProjectSpace/#what-is-a-project-space","title":"What is a Project Space?","text":"<p>Users can work with files in two different main directories. The first is their personal home directory, found in <code>/home/[username]</code>. The second is within a project directory, found in <code>/project/[project_name]</code>. These project directories provide a space where files can easily be shared and analyzed with collaborators. Using the Group Management tools, users can designate a list of others who can access their files. These designated individuals, if also given an account on the Science Portal, may interact with the files using the various session types available. These features enable truly collaborative work, e.g., allowing a team to jointly reduce large quantities of data from a project.</p>"},{"location":"general/NewUser/ProjectSpace/#how-to-request-a-project-space","title":"How to Request a Project Space","text":"<p>In order to request a project space, you will need to have a name for the space (the name of the project directory). As with home directories, the default diskspace allocation is 200GB. If you anticipate needing more than this (e.g., working with large datasets such as from ALMA or the VLA), you will need an estimate of the amount of diskspace that you will need. (Requests to change the diskspace allocation at a later date are also possible.) Once you have this information, if you are on the Discord workspace, the easiest way to request a project space is to post the request there, with a note to Kevin Casteels. Alternatively, you can email the request to <code>support@canfar.net</code></p>"},{"location":"general/NewUser/ProjectSpace/#how-to-give-collaborators-access","title":"How to Give Collaborators Access","text":"<p>Collaborators will require a free CADC account in order to be added as people with designated access to the project space files. A CADC account can be requested at https://www.cadc-ccda.hia-iha.nrc-cnrc.gc.ca/en/auth/request.html If your collaborators only wish to download the files and analyze them on their own computers, this step is sufficient; they can access the files on the web at https://www.canfar.net/storage/arc/list/project/[project_name] or use the VOS Tools to download them. If your collaborators wish to work on the files directly on the Science Portal, they will need to request an account on the system, either through emailing <code>support@canfar.net</code> or you can post a request on the slack channel on their behalf (please include their CADC username and the project that you'd like them to have access to).</p> <p>Finally, you can manage which users are able to access your files on the project space using the Group Management tools.</p>"},{"location":"general/Notebook/transfer_file/","title":"Transfer file into Notebook session","text":"<p>Smaller files can be uploaded into a Notebook session easily in two different ways. These are outlined in turn below.</p>"},{"location":"general/Notebook/transfer_file/#directly-upload-the-file","title":"Directly Upload the File","text":"<p>Once you have navigated into your directory of interest using the browser in the left-hand side, click the upward-pointing arrow on the top menu bar.</p> <p></p> <p>This will bring up a window that will let you select the file you wish to upload. Click the <code>Open</code> button as usual to confirm your choice of files.</p> <p></p> <p>Success! Your file is now visible in the browser, and would also be accessible in the same location in a Desktop or a CARTA session.</p> <p></p>"},{"location":"general/Notebook/transfer_file/#copy-paste-text","title":"Copy-Paste Text","text":"<p>Alternatively, you can copy and paste text directly into a a file within your Notebook session. This might be prefered if, for example, you want to copy a snippet of code into an already existing file in your session. Start by opening up a terminal by double-clicking on the icon.</p> <p></p> <p>This opens a terminal on the right hand side of the screen which you can interact with as usual. In the example shown, the text editor vi is being initiated on the command line.</p> <p></p> <p>On your local computer, you would select and copy the text of interest.</p> <p></p> <p>You can then paste this text into a text editor in the terminal.</p> <p></p> <p>Once the file is saved, it is accessible from the file browser in the current directory, and would be visible in a Desktop or a CARTA session as well.</p> <p></p>"},{"location":"general/TipsTricks/Direct_url/","title":"Direct URL Upload/Download","text":"<p>A direct url is available for files on the /arc storage system, i.e., those in the home or project directories of the Science Portal. A file in your home directory would be located at <code>https://ws-uv.canfar.net/arc/files/home/[username]/[myfile]</code> and similarly a file in your project directory would be located at <code>https://ws-uv.canfar.net/arc/files/projects/[projectname]/[myfile]</code></p> <p>You can upload or download files directly using this URL, but note that all uploads will require authentication and write permission at the target directory, while downloads may require authentication, depending on the read permissions of the file.</p> <p>Here is an example of how to use the curl command to upload a file called <code>myfile.txt</code> from your local computer to your home directory on the Science Portal. First, make sure your permissions are set up, supplying your CADC password at the prompt:</p> <pre><code>cadc-get-cert -u [username]\n</code></pre> <p>Then upload the file:</p> <pre><code>curl -E ~/.ssl/cadcproxy.pem https://ws-uv.canfar.net/arc/files/home/[username]/myfile.txt -T myfile.txt\n</code></pre>"},{"location":"general/TipsTricks/Increase_font/","title":"Increase Font Size of Desktop Containers","text":"<p>Some users may find the default font size for containers in the Desktop session (such as the terminal) too small to easily read.</p> <p></p> <p>The font size can be easily adjusted by holding the control key and clicking anywhere in the terminal. This brings up a pop-up menu that allows you to select a different font size.</p> <p></p> <p>The following image shows the resulting increase in font size if the <code>Large</code> option is chosen.</p> <p></p>"},{"location":"general/TipsTricks/Using_clipboard/","title":"Copy &amp; Paste Between Desktop Containers","text":"<p>Since the different containers (e.g., CASA and terminal windows) on a Desktop session may not be running on the same remote computer, copying and pasting text from one container into another is not quite as simple as when using a personal desktop machine. To copy and paste within a Desktop session, you need to make use of an intermediary application called the Clipboard. To find the Clipboard, click on the arrow at the far left of the Desktop.</p> <p></p> <p>This brings up a menu with several different applications. The Clipboard is in about the middle of the list and can be opened by clicking on it.</p> <p></p> <p>The image below shows an open Clipboard ready for use.</p> <p></p> <p>The Clipboard functions as an intermediary place to put text that you wish to transfer from one container session to another. You can copy highlighted / selected text using Control-Shift-C, and paste it using Control-Shift-V.</p> <p>In the example here, a line of code is being copied from a python program (being edited in a normal terminal window) into a running interactive CASA session. In the first step, the text is highlighted in the terminal window. Usually, this highlighted text directly transfers into the Clipboard.</p> <p></p> <p>Next, highlight the text on the Clipboard, and type Control-Shift-C. Then, click on the CASA terminal and type Control-Shift-V to paste the text there.</p> <p></p> <p>This same process applies to all other copy-paste needs as well, for example, from a web browser window into a terminal.</p>"}]}